# AutoMem MCP: Give Your AI Perfect Memory üß†

[![Version](https://img.shields.io/npm/v/@verygoodplugins/mcp-automem)](https://www.npmjs.com/package/@verygoodplugins/mcp-automem)
[![License](https://img.shields.io/npm/l/@verygoodplugins/mcp-automem)](LICENSE)

> **‚ö†Ô∏è Beta Notice:** The MCP server and AutoMem cloud service are stable and production-ready. However, platform-specific integrations (Cursor hooks, Claude Code automation, etc.) are actively evolving as we optimize based on new LLM capabilities and real-world usage. Expect frequent updates and improvements.

**One command. Infinite memory. Perfect recall across all your AI tools.**

```bash
npx @verygoodplugins/mcp-automem setup
```

Your AI assistant now remembers everything. Forever. Across every conversation.

Works with **Claude Desktop**, **Cursor IDE**, **Claude Code** - any MCP-compatible AI platform.

---

## The Problem We Solve

Every AI conversation starts from zero. Claude forgets your coding style. Cursor can't learn your patterns. Your assistant doesn't remember yesterday's decisions.

**Until now.**

AutoMem MCP connects your AI to persistent memory powered by **[AutoMem](https://github.com/verygoodplugins/automem)** - a graph-vector memory service validated by cutting-edge research (HippoRAG 2, A-MEM, MELODI).

## What You Get

### üß† Persistent Memory Across Sessions
- AI remembers decisions, patterns, and context **forever**
- Works across **all MCP platforms** - Claude Desktop, Cursor, Claude Code
- **Cross-device sync** - same memory on Mac, Windows, Linux

### üèÜ Graph-Vector Architecture
- **11 relationship types** between memories (not just similarity)
- **Research-validated** approach (HippoRAG 2: 7% better associative memory)
- **Sub-second retrieval** even with millions of memories

### üöÄ Works Everywhere You Code

| Platform | Support | Setup Time |
|----------|---------|------------|
| **Claude Desktop** | ‚úÖ Full | 30 seconds |
| **Cursor IDE** | ‚úÖ Full | 30 seconds |
| **Claude Code** | ‚ö†Ô∏è Experimental + Auto-capture hooks | 1 minute |
| **Warp Terminal** | ‚úÖ Full + Context-aware | 30 seconds |
| **OpenAI Codex** | ‚úÖ Full | 30 seconds |
| **Any MCP client** | ‚úÖ Full | 30 seconds |

## See It In Action

### Claude Desktop with Custom Instructions
![Claude Desktop Using Memory](screenshots/claude-desktop-with-instructions.jpg)
*Claude automatically recalls memories at conversation start using custom instructions*

### Cursor IDE with Memory Rules
![Cursor with Memory](screenshots/cursor-2.jpg)
*Cursor uses automem.mdc rule to automatically recall and store memories*

### Claude Code with Session Memory
![Claude Code Memory Capture](screenshots/claude-code-1.jpg)
*Git commits, builds, and deployments automatically stored to memory*

### OpenAI Codex with Memory Rules
*OpenAI Codex uses config.toml to automatically recall and store memories*

### Warp Terminal with Memory Rules
![Warp Terminal with Memory](screenshots/warp-tool-2.jpg)
*Warp Terminal uses memory rules to automatically recall and store context*

### Your AI Learns Your Code Style
```javascript
// After 1 week, your AI writes EXACTLY like you
// ‚úÖ It knows you prefer early returns
// ‚úÖ It uses your specific variable naming
// ‚úÖ It matches your comment style
// ‚úÖ It follows YOUR patterns, not generic best practices
```

### Decisions That Feel Like Yours
```
User: "Should we use Redis for this?"

Without AutoMem:
"Consider RabbitMQ, Kafka, or AWS SQS based on your needs..."

With AutoMem:
"Based on your pattern of preferring boring technology that works,
and your positive experience with Redis in Project X (March 2024), 
yes. You specifically value operational simplicity over feature 
richness - Redis fits perfectly."
```

## Quick Start

### 1. Run AutoMem Service Locally

**Best for:** Getting started, development, testing, or if you don't need cross-device sync.

```bash
# Clone AutoMem service repository
git clone https://github.com/verygoodplugins/automem.git
cd automem

# Start all services (API + FalkorDB + Qdrant)
make dev
```

**What just happened?** Docker Compose started three containers:
- **AutoMem API** at `http://localhost:8001` - Memory storage/retrieval service
- **FalkorDB** at `localhost:6379` - Graph database for memory relationships
- **Qdrant** at `localhost:6333` - Vector database for semantic search

**Verify it's running:**
```bash
curl http://localhost:8001/health
# Expected: {"status": "healthy", "falkordb": "connected"}
```

**Default credentials (local only):**
- No API token required for local development
- Service listens on `127.0.0.1` only (not accessible from network)

**Persistent storage:**
- Memories stored in Docker volumes (survive container restarts)
- To reset: `make clean` (‚ö†Ô∏è deletes all memories)

üëâ **[Full Local Setup Guide](https://github.com/verygoodplugins/automem/blob/main/INSTALLATION.md)** for advanced configuration

---

### 2. Install MCP Client

Connect your AI tools to the AutoMem service you just started.

```bash
# Guided setup - creates .env and prints config for your AI platform
npx @verygoodplugins/mcp-automem setup
```

**When prompted:**
- **AutoMem Endpoint:** `http://localhost:8001` (or your Railway URL if deployed)
- **API Key:** Leave blank for local development (or paste your token for Railway)

The wizard will:
- ‚úÖ Save your endpoint and API key to `.env`
- ‚úÖ Generate config snippets for Claude Desktop/Cursor/Code
- ‚úÖ Validate connection to your AutoMem service

### 3. Platform-Specific Setup

**For Claude Desktop:**
```bash
# Setup prints config snippet - just paste into claude_desktop_config.json
npx @verygoodplugins/mcp-automem setup
```

**For Cursor IDE:**

[![Install MCP Server](https://cursor.com/deeplink/mcp-install-light.svg)](cursor://anysphere.cursor-deeplink/mcp/install?name=memory&config=eyJlbnYiOnsiQVVUT01FTV9FTkRQT0lOVCI6Imh0dHA6Ly8xMjcuMC4wLjE6ODAwMSIsIkFVVE9NRU1fQVBJX0tFWSI6InlvdXItYXBpLWtleS1pZi1yZXF1aXJlZCJ9LCJjb21tYW5kIjoibnB4IEB2ZXJ5Z29vZHBsdWdpbnMvbWNwLWF1dG9tZW0ifQ%3D%3D)

```bash
# Or use CLI to install automem.mdc rule file
npx @verygoodplugins/mcp-automem cursor
```

> **Note:** After one-click install, configure your `AUTOMEM_ENDPOINT` in `~/.cursor/mcp.json` or Claude Desktop config

**For Claude Code:**
```bash
# Installs automation hooks that capture memories automatically
npx @verygoodplugins/mcp-automem claude-code
```

**For Warp Terminal:**
See the Warp setup guide and add the MCP configuration from `templates/warp/mcp.json` to your `~/.warp/mcp.json`.
Follow usage rules in `templates/warp/warp-rules.md`.

**For OpenAI Codex:**
```bash
# Add to your Codex MCP configuration
npx @verygoodplugins/mcp-automem config --format=json
 
# Optional: add memory-first rules to this repo
npx @verygoodplugins/mcp-automem codex
```

üëâ **[Full Installation Guide](INSTALLATION.md)** for detailed setup instructions

---

## Optional: Deploy to Railway

**Should you deploy to Railway?** It depends on your use case:

### ‚úÖ Deploy to Railway if you:
- **Use multiple devices** - Access same memories from laptop, desktop, mobile
- **Collaborate with a team** - Share memories across team members
- **Want always-on availability** - Don't want to start Docker containers daily
- **Need remote access** - Use Claude on a tablet/phone without local services
- **Value simplicity** - Set it once, forget about it ($5/month hands-off)

### üè† Stick with local if you:
- **Work on one machine** - Don't need cross-device sync
- **Privacy first** - Keep all memories on your hardware
- **Have Docker skills** - Comfortable managing local services
- **Prefer zero cost** - No cloud bills, just local compute
- **Developing/testing** - Local is faster for iteration

---

### Railway Deployment Guide

**What is Railway?** Cloud hosting platform - like Heroku but modern. Your AutoMem service runs 24/7 in a container.

**Cost breakdown:**
- ‚úÖ **$5 free credits** for 30-day trial (no credit card)
- ‚úÖ **~$0.50/month** typical AutoMem usage after trial
- ‚úÖ **$1/month minimum** if you use less

---

#### Option A: One-Click Deploy ‚≠ê (Recommended)

[![Deploy on Railway](https://railway.com/button.svg)](https://railway.com/deploy/yD_u9d?referralCode=VuFE6g&utm_medium=integration&utm_source=template&utm_campaign=generic)

**What this does:**
- Creates AutoMem API + FalkorDB services automatically
- Sets up persistent storage
- Generates secure API tokens
- Configures networking

**After clicking:**
1. Sign in with GitHub (if not logged in)
2. (Optional) Add `OPENAI_API_KEY` for real embeddings
3. Click **"Deploy"**
4. Wait 60 seconds ‚Üí Done! ‚úÖ

Then jump to [Step 3: Get Your AutoMem URL](#step-3-get-your-automem-url-1-minute) below.

---

#### Option B: Manual Setup

<details>
<summary><b>Prefer manual control? Click to expand manual setup steps</b></summary>

#### Step 1: Create Railway Account (2 minutes)

1. Go to **[railway.app](https://railway.app)**
2. Click **"Start a New Project"** or **"Login"**
3. Sign in with GitHub (create GitHub account first if needed)

---

#### Step 2: Deploy AutoMem Service (5 minutes)

AutoMem runs as **two services** on Railway: the API and FalkorDB database.

**2a. Create New Project**

1. After logging in, click **"New Project"**
2. Choose **"Deploy from GitHub repo"**

**2b. Connect GitHub Repository**

1. Click **"Configure GitHub App"**
2. Install Railway app to your GitHub account
3. Fork **[verygoodplugins/automem](https://github.com/verygoodplugins/automem)** (top right, click "Fork")
4. Back in Railway, select **your fork** of automem
5. Click **"Deploy Now"**

**2c. Add FalkorDB Database**

Railway will deploy the AutoMem API automatically. Now add the database:

1. In your project, click **"+ New"** ‚Üí **"Empty Service"**
2. In the new service settings:
   - **Name:** `falkordb`
   - **Source:** Docker image
   - **Image:** `falkordb/falkordb:latest`
3. Click **"Deploy"**

**2d. Configure AutoMem API Environment Variables**

1. Click on your **automem** service (not falkordb)
2. Go to **"Variables"** tab
3. Click **"+ New Variable"** and add these:

| Variable | Value | Description |
|----------|-------|-------------|
| `AUTOMEM_API_TOKEN` | Generate a random string* | Auth token for API calls |
| `ADMIN_API_TOKEN` | Generate another random string* | Admin-only operations |
| `FALKORDB_HOST` | `falkordb.railway.internal` | Internal FalkorDB hostname |
| `FALKORDB_PORT` | `6379` | FalkorDB port |
| `OPENAI_API_KEY` | Your OpenAI API key (optional) | Enables real embeddings |

**Generate random strings:* Use `openssl rand -base64 32` in terminal or any password generator.

**Optional:** Add `QDRANT_URL` and `QDRANT_API_KEY` if using Qdrant Cloud for vector search.

4. Click **"Deploy"** to restart with new variables

---

#### Step 3: Get Your AutoMem URL (1 minute)

1. Click on your **automem** service (the API, not falkordb)
2. Go to **"Settings"** tab
3. Scroll to **"Networking"** ‚Üí **"Public Networking"**
4. Click **"Generate Domain"**
5. **Copy the URL** - looks like: `automem-production-abc123.up.railway.app`

**‚úÖ Save this URL!** You'll need it when you run `npx @verygoodplugins/mcp-automem setup`

---

#### Step 4: Verify Deployment (30 seconds)

Test that everything works:

```bash
# Replace with YOUR Railway URL
curl https://automem-production-abc123.up.railway.app/health
```

**Expected response:**
```json
{"status": "healthy", "falkordb": "connected"}
```

**Got an error?**
- `503 Service Unavailable` = FalkorDB can't connect. Check:
  - `FALKORDB_HOST` is set to `falkordb.railway.internal`
  - FalkorDB service is running (green dot in Railway dashboard)
  - Volume is mounted at `/data`
- `401 Unauthorized` = You're trying a protected endpoint. `/health` should work without auth.

---

#### Step 5: Update MCP Client Configuration

Now point your MCP client to Railway instead of localhost:

```bash
# Re-run setup with your Railway URL
npx @verygoodplugins/mcp-automem setup
```

**When prompted:**
- **AutoMem Endpoint:** `https://automem-production-abc123.up.railway.app` (your URL)
- **API Key:** Paste your `AUTOMEM_API_TOKEN` from Step 2e

That's it! Your AI tools now connect to Railway instead of localhost.

</details>

---

#### What You Just Built

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Railway Cloud (Your Free Tier)    ‚îÇ
‚îÇ                                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ  AutoMem API   ‚îÇ  ‚îÇ FalkorDB  ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  (Flask)       ‚îÇ‚îÄ‚îÄ‚îÇ (Graph DB)‚îÇ ‚îÇ
‚îÇ  ‚îÇ  Port: 443     ‚îÇ  ‚îÇ +Volume   ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ         ‚ñ≤                           ‚îÇ
‚îÇ         ‚îÇ HTTPS                     ‚îÇ
‚îÇ         ‚îÇ (your-url.railway.app)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ
          ‚ñº
   Your AI Tools
   (any device, anywhere)
```

üëâ **[Full Railway Deployment Guide](RAILWAY_TEMPLATE_GUIDE.md)** for advanced configuration and troubleshooting

---

## What Happens Next

| Timeline | What Your AI Learns |
|----------|-------------------|
| **Hour 1** | Starts capturing your patterns |
| **Day 1** | Learns your decision factors |
| **Day 3** | Recognizes your coding style |
| **Week 1** | Writes in your voice |
| **Week 2** | Makes decisions like you would |

## Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         Your AI Platforms                   ‚îÇ
‚îÇ  Claude Desktop ‚îÇ Cursor ‚îÇ Claude Code      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ MCP Protocol
               ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   @verygoodplugins/mcp-automem (this pkg)   ‚îÇ
‚îÇ   ‚Ä¢ Translates MCP calls ‚Üí AutoMem API      ‚îÇ
‚îÇ   ‚Ä¢ Handles authentication                   ‚îÇ
‚îÇ   ‚Ä¢ Manages memory lifecycle                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ HTTP API
               ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ        AutoMem Service                       ‚îÇ
‚îÇ        github.com/verygoodplugins/automem    ‚îÇ
‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îÇ
‚îÇ   ‚îÇ  FalkorDB  ‚îÇ      ‚îÇ   Qdrant   ‚îÇ        ‚îÇ
‚îÇ   ‚îÇ  (Graph)   ‚îÇ      ‚îÇ (Vectors)  ‚îÇ        ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**This package** = MCP client that connects your AI to AutoMem  
**[AutoMem service](https://github.com/verygoodplugins/automem)** = Backend with FalkorDB + Qdrant

## Features

### Core Memory Operations
- **`store_memory`** - Save memories with content, tags, importance, metadata
- **`recall_memory`** - Hybrid search (vector + keyword + tags + time)
- **`associate_memories`** - Create relationships (RELATES_TO, LEADS_TO, etc.)
- **`update_memory`** - Modify existing memories
- **`delete_memory`** - Remove memories
- **`check_database_health`** - Monitor service status

### Platform Integrations

#### Cursor IDE
- ‚úÖ **Memory-first rule file** (`automem.mdc` in `.cursor/rules/`)
- ‚úÖ **Automatic memory recall** at conversation start
- ‚úÖ **Auto-detects project context** (package.json, git remote)
- ‚úÖ **Global user rules option** for all projects
- ‚úÖ **Simple setup** via CLI or one-click install

#### Claude Code
- ‚úÖ **Automatic session capture** (git commits, builds, tests, deploys)
- ‚úÖ **Queue-based processing** with deduplication (non-blocking)
- ‚úÖ **Smart filtering** (skips trivial files, lock files, build artifacts)
- ‚úÖ **Configurable profiles** (lean/extras)
- ‚úÖ **Relationship tracking** between memories
- ‚úÖ **Efficient defaults** (~1-2 captures/session, high signal-to-noise)

#### Claude Desktop
- ‚úÖ Direct MCP integration
- ‚úÖ Manual and automated workflows
- ‚úÖ Full memory API access

#### Warp Terminal
- ‚úÖ Project context auto-detection
- ‚úÖ Memory-first terminal assistance
- ‚úÖ Smart recall on directory changes
- ‚úÖ Command history with context

## Why AutoMem MCP?

### vs. Building Your Own
- ‚úÖ **2 years of R&D** already done
- ‚úÖ **Research-validated** architecture (HippoRAG 2, MELODI, A-MEM)
- ‚úÖ **Working integrations** across all MCP platforms
- ‚úÖ **Active development** and community

### vs. Other Memory Solutions
- ‚úÖ **True graph relationships** (not just vector similarity)
- ‚úÖ **Universal MCP compatibility** (works with any MCP client)
- ‚úÖ **7 memory types** (Decision/Pattern/Preference/Style/Habit/Insight/Context)
- ‚úÖ **Self-hostable** ($5/month vs $150+ for alternatives)

### vs. Native AI Memory
- ‚úÖ **Persistent across sessions** (not just context window)
- ‚úÖ **Cross-platform** (same memory in Claude, Cursor, Code)
- ‚úÖ **Structured relationships** (not just RAG)
- ‚úÖ **Infinite scale** (no context window limits)

## Real-World Results

### Code Review That Knows Your Standards
```
Before AutoMem:
"Consider adding error handling here."

After AutoMem:
"Missing your standard try/except pattern. Based on your PR#127
review comments, you always wrap database calls with specific
logging for timeouts. Apply the same pattern here?"
```

### Decisions With Context
```
Before AutoMem:
"Both approaches have tradeoffs..."

After AutoMem:
"You chose PostgreSQL over MongoDB for similar use case in Q1 2024.
Your decision memo cited team expertise and operational simplicity.
Same factors apply here - go with Postgres."
```

## Documentation

- üì¶ **[Installation Guide](INSTALLATION.md)** - Detailed setup for all platforms
- üîß **[Configuration](INSTALLATION.md#configuration)** - Environment variables, advanced options
- üéØ **[Cursor Setup](INSTALLATION.md#cursor-ide)** - IDE integration guide
- ü§ñ **[Claude Code Hooks](templates/CLAUDE_CODE_INTEGRATION.md)** - Automation setup
- üíª **[Warp Terminal Setup](INSTALLATION.md#warp-terminal)** - Terminal integration guide
- üöÄ **[OpenAI Codex Setup](INSTALLATION.md#openai-codex)** - Codex CLI/IDE/Cloud agent integration
- üìñ **[API Reference](INSTALLATION.md#mcp-tools)** - All memory operations
- üèóÔ∏è **[AutoMem Service](https://github.com/verygoodplugins/automem)** - Backend deployment

## The Science Behind AutoMem

The AutoMem service implements cutting-edge 2025 research:

- **[HippoRAG 2](https://arxiv.org/abs/2502.14802)** (OSU, June 2025): Graph-vector approach achieves 7% better associative memory
- **A-MEM** (July 2025): Dynamic memory organization with Zettelkasten principles  
- **MELODI** (DeepMind, 2025): 8x memory compression without quality loss
- **ReadAgent** (DeepMind, 2024): 20x context extension through gist memories

This MCP package provides the bridge between your AI and that research-validated memory system.

## Community & Support

- üì¶ **[NPM Package](https://www.npmjs.com/package/@verygoodplugins/mcp-automem)** - This MCP client
- üî¨ **[AutoMem Service](https://github.com/verygoodplugins/automem)** - Backend repo with deployment guides
- üêõ **[GitHub Issues](https://github.com/verygoodplugins/mcp-automem/issues)** - Bug reports and feature requests
- üê¶ **[@verygoodplugins](https://x.com/verygoodplugins)** - Updates and announcements

## Quick Links

- [Installation Guide](INSTALLATION.md) - Complete setup instructions
- [Cursor Setup](INSTALLATION.md#cursor-ide) - IDE integration
- [Claude Code Integration](templates/CLAUDE_CODE_INTEGRATION.md) - Automation hooks
- [Warp Terminal Setup](INSTALLATION.md#warp-terminal) - Terminal integration
- [OpenAI Codex Setup](INSTALLATION.md#openai-codex) - Codex integration
- [AutoMem Service Deployment](https://github.com/verygoodplugins/automem#deployment) - Backend setup
- [Changelog](CHANGELOG.md) - Release history

## Contributing

We welcome contributions! Please:

1. Fork the repository
2. Create a feature branch
3. Make your changes with tests
4. Submit a pull request

## License

MIT - Because great memory should be free.

---

**Ready to give your AI perfect memory?**

```bash
npx @verygoodplugins/mcp-automem setup
```

*Built with obsession. Validated by neuroscience. Powered by graph theory. Works with every MCP-enabled AI.*

*Designed by Jack Arturo at [Very Good Plugins](https://verygoodplugins.com)* üß°

**Transform your AI from a tool into a teammate. Start now.**
